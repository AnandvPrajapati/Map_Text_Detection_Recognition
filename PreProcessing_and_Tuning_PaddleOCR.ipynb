{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!python -m pip install paddlepaddle-gpu==2.0.0 -i https://mirror.baidu.com/pypi/simple\n",
    "!python -m pip install paddlepaddle -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install paddleocr opencv-python matplotlib scikit-image numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import exposure, filters\n",
    "\n",
    "# Preprocessing functions as defined above\n",
    "def preprocess_historical_map(image):\n",
    "    \"\"\"Basic preprocessing for historical maps\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    equalized = clahe.apply(gray)\n",
    "    \n",
    "    denoised = cv2.bilateralFilter(equalized, 9, 75, 75)\n",
    "    \n",
    "    kernel = np.array([[-1, -1, -1],\n",
    "                       [-1,  9, -1],\n",
    "                       [-1, -1, -1]])\n",
    "    sharpened = cv2.filter2D(denoised, -1, kernel)\n",
    "    \n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    \n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    dilated = cv2.dilate(opening, kernel, iterations=1)\n",
    "    \n",
    "    return dilated\n",
    "\n",
    "\n",
    "def advanced_map_preprocessing(image):\n",
    "    \"\"\"Advanced preprocessing techniques for historical maps\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        gray = image.copy()\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    filtered = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
    "    \n",
    "    edges = cv2.Canny(filtered, 50, 150)\n",
    "    \n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    mask = dilated_edges.copy()\n",
    "    \n",
    "    masked = cv2.bitwise_and(filtered, filtered, mask=mask)\n",
    "    \n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        filtered, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 7\n",
    "    )\n",
    "    \n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    inverted = cv2.bitwise_not(cleaned)\n",
    "    \n",
    "    return inverted\n",
    "\n",
    "\n",
    "def adaptive_map_preprocessing(image):\n",
    "    \"\"\"Dynamically adjust preprocessing based on image characteristics\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    mean_val = np.mean(gray)\n",
    "    std_val = np.std(gray)\n",
    "    \n",
    "    if std_val < 50:  # Low contrast image\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    else:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    if std_val > 60:  # High variation indicates possible noise\n",
    "        denoised = cv2.medianBlur(enhanced, 3)\n",
    "    else:\n",
    "        denoised = cv2.GaussianBlur(enhanced, (3, 3), 0)\n",
    "    \n",
    "    gaussian = cv2.GaussianBlur(denoised, (0, 0), 3.0)\n",
    "    unsharp_image = cv2.addWeighted(denoised, 1.5, gaussian, -0.5, 0)\n",
    "    \n",
    "    if mean_val < 100:  # Darker image\n",
    "        binary = cv2.adaptiveThreshold(\n",
    "            unsharp_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "            cv2.THRESH_BINARY, 13, 4\n",
    "        )\n",
    "    else:  # Brighter image\n",
    "        binary = cv2.adaptiveThreshold(\n",
    "            unsharp_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "            cv2.THRESH_BINARY, 11, 2\n",
    "        )\n",
    "    \n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def text_enhanced_preprocessing(image):\n",
    "    \"\"\"Preprocessing focused on enhancing text in maps with complex backgrounds\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    contrast_enhanced = clahe.apply(gray)\n",
    "    \n",
    "    median_blurred = cv2.medianBlur(contrast_enhanced, 3)\n",
    "    \n",
    "    laplacian = cv2.Laplacian(median_blurred, cv2.CV_64F)\n",
    "    \n",
    "    laplacian = np.uint8(np.absolute(laplacian))\n",
    "    \n",
    "    _, edges = cv2.threshold(laplacian, 15, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    masked = cv2.bitwise_and(contrast_enhanced, contrast_enhanced, mask=dilated_edges)\n",
    "    \n",
    "    thresh = cv2.adaptiveThreshold(masked, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                  cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "\n",
    "def setup_optimized_ocr_model():\n",
    "    \"\"\"Setup and return an OCR model with optimized parameters for historical maps\"\"\"\n",
    "    ocr_model = PaddleOCR(\n",
    "        # Use English language model\n",
    "        lang='en',\n",
    "        \n",
    "        # Enable angle classification to detect rotated text\n",
    "        use_angle_cls=True,\n",
    "        \n",
    "        # Set a lower detection threshold to catch more potential text\n",
    "        det_db_thresh=0.1,\n",
    "        \n",
    "        # Set a lower text recognition threshold\n",
    "        rec_thresh=0.45,\n",
    "        \n",
    "        # Optimize text detector parameters for faint text\n",
    "        det_db_box_thresh=0.3,\n",
    "        \n",
    "        # Use a larger unclip ratio to better separate adjacent text\n",
    "        det_db_unclip_ratio=1.8,\n",
    "        \n",
    "        # Enable using GPU if available\n",
    "        use_gpu=True,\n",
    "        \n",
    "        # Set the maximum image size for text detection\n",
    "        det_limit_side_len=2000,\n",
    "        \n",
    "        # Enable text direction classification\n",
    "        cls_thresh=0.9\n",
    "    )\n",
    "    return ocr_model\n",
    "\n",
    "\n",
    "def process_image_with_multiple_methods(img_path, ocr_model):\n",
    "    \"\"\"\n",
    "    Process an image with multiple preprocessing methods and compare OCR results.\n",
    "    \"\"\"\n",
    "    original_img = cv2.imread(img_path)\n",
    "    if original_img is None:\n",
    "        print(f\"Error: Could not read image at {img_path}\")\n",
    "        return None, None, {}\n",
    "    \n",
    "    output_dir = os.path.dirname(img_path) + \"/preprocessed\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Define preprocessing methods\n",
    "    methods = {\n",
    "        \"original\": img_rgb,\n",
    "        \"basic_preprocessing\": cv2.cvtColor(preprocess_historical_map(original_img), cv2.COLOR_GRAY2RGB),\n",
    "        \"advanced_preprocessing\": cv2.cvtColor(advanced_map_preprocessing(original_img), cv2.COLOR_GRAY2RGB),\n",
    "        \"adaptive_preprocessing\": cv2.cvtColor(adaptive_map_preprocessing(original_img), cv2.COLOR_GRAY2RGB),\n",
    "        \"text_enhanced\": cv2.cvtColor(text_enhanced_preprocessing(original_img), cv2.COLOR_GRAY2RGB)\n",
    "    }\n",
    "    \n",
    "    all_results = {}\n",
    "    best_method = \"original\"\n",
    "    best_count = 0\n",
    "    best_confidence = 0\n",
    "    best_result = None\n",
    "    \n",
    "    for method_name, processed_img in methods.items():\n",
    "        print(f\"Processing with {method_name}...\")\n",
    "        \n",
    "        base_name = os.path.basename(img_path).split('.')[0]\n",
    "        processed_path = f\"{output_dir}/{base_name}_{method_name}.jpg\"\n",
    "        cv2.imwrite(processed_path, \n",
    "                    cv2.cvtColor(processed_img, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        result = ocr_model.ocr(processed_img, cls=True)\n",
    "        \n",
    "        all_results[method_name] = result\n",
    "        \n",
    "        if result and result[0]:\n",
    "            text_count = len(result[0])\n",
    "            \n",
    "            if text_count > 0:\n",
    "                avg_confidence = sum(res[1][1] for res in result[0]) / text_count\n",
    "            else:\n",
    "                avg_confidence = 0\n",
    "                \n",
    "            print(f\"  - Detected {text_count} text regions with avg confidence {avg_confidence:.4f}\")\n",
    "            \n",
    "            # Choose the best method based on text count and confidence\n",
    "            if text_count > best_count or (text_count == best_count and avg_confidence > best_confidence):\n",
    "                best_count = text_count\n",
    "                best_confidence = avg_confidence\n",
    "                best_method = method_name\n",
    "                best_result = result\n",
    "        else:\n",
    "            print(f\"  - No text detected with {method_name}\")\n",
    "    \n",
    "    print(f\"\\nBest method: {best_method} with {best_count} texts detected\")\n",
    "    return best_result, best_method, all_results\n",
    "\n",
    "def process_folder(folder_path, output_json_path=\"map_ocr_results.json\"):\n",
    "    \"\"\"Process all images in a folder, apply preprocessing, and save OCR results.\"\"\"\n",
    "    ocr_model = setup_optimized_ocr_model()\n",
    "\n",
    "    try:\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        script_dir = os.getcwd()\n",
    "    \n",
    "    font_path = None\n",
    "    possible_font_paths = [\n",
    "        os.path.join(os.path.join(script_dir, 'PaddleOCR', 'doc', 'fonts', 'latin.ttf')),\n",
    "        # Check in current working directory\n",
    "        os.path.join(os.getcwd(), 'latin.ttf'),\n",
    "        # System fonts (Linux/Windows/Mac)\n",
    "        '/usr/share/fonts/truetype/freefont/FreeMono.ttf',\n",
    "        'C:/Windows/Fonts/arial.ttf',\n",
    "        '/System/Library/Fonts/Supplemental/Arial.ttf'\n",
    "    ]\n",
    "    \n",
    "    for path in possible_font_paths:\n",
    "        if os.path.exists(path):\n",
    "            font_path = path\n",
    "            break\n",
    "    \n",
    "    if font_path is None:\n",
    "        print(\"Warning: Using default system font - annotations may not display properly\")\n",
    "        try:\n",
    "            from PIL import ImageFont\n",
    "            font_path = ImageFont.load_default()\n",
    "        except Exception as e:\n",
    "            print(f\"Font loading error: {e}\")\n",
    "            font_path = None\n",
    "\n",
    "    image_files = [f for f in os.listdir(folder_path) \n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "    \n",
    "    output_dir = os.path.join(folder_path, \"processed_results\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    ocr_results = []\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        img_path = os.path.join(folder_path, image_file)\n",
    "        print(f\"\\nProcessing: {img_path}\")\n",
    "        \n",
    "        best_result, best_method, method_results = process_image_with_multiple_methods(\n",
    "            img_path, ocr_model\n",
    "        )\n",
    "        \n",
    "        if best_result is None:\n",
    "            print(f\"Failed to process {image_file}\")\n",
    "            continue\n",
    "        \n",
    "        if best_result and best_result[0]:\n",
    "            output_dir_preproc = os.path.join(folder_path, \"preprocessed\")\n",
    "            base_name = os.path.basename(img_path).split('.')[0]\n",
    "            best_img_path = f\"{output_dir_preproc}/{base_name}_{best_method}.jpg\"\n",
    "            best_img = cv2.imread(best_img_path)\n",
    "            best_img_rgb = cv2.cvtColor(best_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            boxes = [line[0] for line in best_result[0]]\n",
    "            texts = [line[1][0] for line in best_result[0]]\n",
    "            scores = [line[1][1] for line in best_result[0]]\n",
    "            \n",
    "            try:\n",
    "                annotated = draw_ocr(best_img_rgb, boxes, texts, scores, font_path=font_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Annotation error: {e}\")\n",
    "                annotated = best_img_rgb\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{base_name}_annotated.jpg\")\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.title(f\"OCR Results for {image_file}\")\n",
    "            plt.imshow(annotated)\n",
    "            plt.axis(\"off\")\n",
    "            plt.savefig(output_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Saved annotated image to {output_path}\")\n",
    "            \n",
    "            groups = []\n",
    "            for line in best_result[0]:\n",
    "                box, (text, score) = line\n",
    "                vertices = [[float(x), float(y)] for x, y in box]\n",
    "                \n",
    "                groups.append({\n",
    "                    \"vertices\": vertices,\n",
    "                    \"text\": text,\n",
    "                    \"illegible\": False,\n",
    "                    \"truncated\": False\n",
    "                })\n",
    "            \n",
    "            ocr_results.append({\n",
    "                \"image\": os.path.join('rumsey/val/', image_file).replace(\"\\\\\", \"/\"), #Modify path as you want to store into results.json\n",
    "                \"groups\": [groups]\n",
    "            })\n",
    "    \n",
    "    # Save to JSON file\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(ocr_results, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nSaved OCR results to {output_json_path}\")\n",
    "    return ocr_results\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to process all images in the specified folder\"\"\"\n",
    "    folder_path = '\"path/to/images\"' #Enter path to directory of images\n",
    "    \n",
    "    # Process all images in the folder\n",
    "    results = process_folder(folder_path, \"path/to/save/the/results.json\")\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Processed {len(results)} images.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
